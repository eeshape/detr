# DETR ì„ë² ë”© ì¶”ì¶œ Output êµ¬ì¡° ìƒì„¸ ì„¤ëª…

## ğŸ“ Output í´ë” êµ¬ì¡°

### ê¸°ë³¸ êµ¬ì¡°
```
embeddings_output/                    # --output_dirë¡œ ì§€ì •í•œ í´ë”
â”œâ”€â”€ metadata.json                     # ë©”íƒ€ë°ì´í„° íŒŒì¼
â”œâ”€â”€ embedding_000000000001.pt         # ì´ë¯¸ì§€ ID 1ì˜ ì„ë² ë”©
â”œâ”€â”€ embedding_000000000002.pt         # ì´ë¯¸ì§€ ID 2ì˜ ì„ë² ë”©
â”œâ”€â”€ embedding_000000000003.pt         # ì´ë¯¸ì§€ ID 3ì˜ ì„ë² ë”©
â””â”€â”€ ...                               # ê° ì´ë¯¸ì§€ë§ˆë‹¤ í•˜ë‚˜ì”©
```

### ì‹¤ì œ ì˜ˆì‹œ (100ê°œ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹œ)
```
embeddings_output/
â”œâ”€â”€ metadata.json                     # 1ê°œ
â”œâ”€â”€ embedding_000000000001.pt         # ì•½ 400KB
â”œâ”€â”€ embedding_000000000002.pt         # ì•½ 400KB
â”œâ”€â”€ embedding_000000000003.pt         # ì•½ 400KB
â”œâ”€â”€ ...
â””â”€â”€ embedding_000000000100.pt         # ì•½ 400KB

ì´ íŒŒì¼: 101ê°œ (metadata.json + 100ê°œ .pt íŒŒì¼)
ì´ ìš©ëŸ‰: ì•½ 40MB (100 ì´ë¯¸ì§€ * 400KB)
```

---

## ğŸ“„ 1. metadata.json

JSON í˜•ì‹ì˜ ë©”íƒ€ì •ë³´ íŒŒì¼ì…ë‹ˆë‹¤.

### ë‚´ìš©
```json
{
  "image_ids": [1, 2, 3, 4, 5, ..., 100],
  "num_images": 100,
  "extract_type": "decoder",
  "embedding_keys": [
    "decoder_output",
    "query_embeddings",
    "pred_logits",
    "pred_boxes"
  ]
}
```

### í•„ë“œ ì„¤ëª…
- **image_ids**: ì¶”ì¶œëœ ëª¨ë“  ì´ë¯¸ì§€ì˜ ID ëª©ë¡
- **num_images**: ì´ ì´ë¯¸ì§€ ê°œìˆ˜
- **extract_type**: ì‚¬ìš©í•œ ì¶”ì¶œ íƒ€ì… (all, decoder, encoder, backbone)
- **embedding_keys**: ê° .pt íŒŒì¼ì— í¬í•¨ëœ í‚¤ ëª©ë¡

---

## ğŸ’¾ 2. embedding_XXXXXXXXXXXX.pt íŒŒì¼ë“¤

ê° ì´ë¯¸ì§€ë§ˆë‹¤ í•˜ë‚˜ì˜ PyTorch íŒŒì¼ (.pt)ì´ ìƒì„±ë©ë‹ˆë‹¤.

### íŒŒì¼ëª… ê·œì¹™
```
embedding_{image_id:012d}.pt
```
- ì´ë¯¸ì§€ IDë¥¼ 12ìë¦¬ë¡œ zero-padding
- ì˜ˆ: ì´ë¯¸ì§€ ID 1 â†’ `embedding_000000000001.pt`
- ì˜ˆ: ì´ë¯¸ì§€ ID 12345 â†’ `embedding_000000012345.pt`

### íŒŒì¼ í˜•ì‹
PyTorch í…ì„œë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ (pickle í˜•ì‹)

---

## ğŸ“Š 3. ê° .pt íŒŒì¼ì˜ ë‚´ìš©

### extract_type='decoder' ì‚¬ìš© ì‹œ (ê¶Œì¥)

```python
{
    'decoder_output': torch.Tensor,      # Shape: [6, 100, 256]
    'query_embeddings': torch.Tensor,    # Shape: [100, 256] â† ê°€ì¥ ì¤‘ìš”!
    'encoder_output': torch.Tensor,      # Shape: [H*W, 256] (ì˜ˆ: [1600, 256])
    'pred_logits': torch.Tensor,         # Shape: [100, 92]
    'pred_boxes': torch.Tensor,          # Shape: [100, 4]
}
```

**Shape ì„¤ëª…:**
- `[6, 100, 256]`: [decoder layers, num_queries, hidden_dim]
- `[100, 256]`: [num_queries, hidden_dim]
- `[1600, 256]`: [height*width, hidden_dim] (feature map í¬ê¸°ì— ë”°ë¼ ë‹¤ë¦„)
- `[100, 92]`: [num_queries, num_classes+1] (COCOëŠ” 91 classes)
- `[100, 4]`: [num_queries, box_coords] (cx, cy, w, h)

### extract_type='all' ì‚¬ìš© ì‹œ

```python
{
    'backbone_features': torch.Tensor,   # Shape: [2048, H, W] (ì˜ˆ: [2048, 25, 34])
    'encoder_output': torch.Tensor,      # Shape: [H*W, 256] (ì˜ˆ: [850, 256])
    'decoder_output': torch.Tensor,      # Shape: [6, 100, 256]
    'query_embeddings': torch.Tensor,    # Shape: [100, 256] â† ê°€ì¥ ì¤‘ìš”!
    'pred_logits': torch.Tensor,         # Shape: [100, 92]
    'pred_boxes': torch.Tensor,          # Shape: [100, 4]
}
```

### extract_type='encoder' ì‚¬ìš© ì‹œ

```python
{
    'encoder_output': torch.Tensor,      # Shape: [H*W, 256]
    'pred_logits': torch.Tensor,         # Shape: [100, 92]
    'pred_boxes': torch.Tensor,          # Shape: [100, 4]
}
```

### extract_type='backbone' ì‚¬ìš© ì‹œ

```python
{
    'backbone_features': torch.Tensor,   # Shape: [2048, H, W]
    'pred_logits': torch.Tensor,         # Shape: [100, 92]
    'pred_boxes': torch.Tensor,          # Shape: [100, 4]
}
```

---

## ğŸ” 4. ê° í…ì„œì˜ ì˜ë¯¸

### 1) query_embeddings (ê°€ì¥ ì¤‘ìš”!) ğŸŒŸ
```
Shape: [100, 256]
Type: torch.FloatTensor
```
- **ì˜ë¯¸**: ê° object queryì˜ ìµœì¢… ì„ë² ë”© ë²¡í„°
- **ì‚¬ìš©ì²˜**: Classification, retrieval, fairness analysis ë“±
- **ì„¤ëª…**: 
  - 100ê°œ = DETRì˜ object queries ê°œìˆ˜
  - 256 = hidden dimension (ì„ë² ë”© ì°¨ì›)
  - ê° queryëŠ” í•˜ë‚˜ì˜ potential objectë¥¼ ë‚˜íƒ€ëƒ„

### 2) decoder_output
```
Shape: [6, 100, 256]
Type: torch.FloatTensor
```
- **ì˜ë¯¸**: ëª¨ë“  decoder layerì˜ hidden states
- **ì‚¬ìš©ì²˜**: Layer-wise ë¶„ì„, ì¤‘ê°„ í‘œí˜„ ì—°êµ¬
- **ì„¤ëª…**:
  - 6 = decoder layers ê°œìˆ˜
  - `decoder_output[-1]` = `query_embeddings` (ë§ˆì§€ë§‰ ë ˆì´ì–´)

### 3) encoder_output
```
Shape: [H*W, 256]
Type: torch.FloatTensor
ì˜ˆ: [850, 256] or [1600, 256]
```
- **ì˜ë¯¸**: Transformer encoderì˜ ì¶œë ¥ (ì „ì—­ context)
- **ì‚¬ìš©ì²˜**: Scene-level í‘œí˜„, spatial reasoning
- **ì„¤ëª…**:
  - H*W = feature mapì˜ spatial í¬ê¸° (ì´ë¯¸ì§€ í¬ê¸°ì— ë”°ë¼ ë‹¤ë¦„)
  - 256 = hidden dimension

### 4) backbone_features
```
Shape: [2048, H, W]
Type: torch.FloatTensor
ì˜ˆ: [2048, 25, 34]
```
- **ì˜ë¯¸**: ResNet backboneì˜ ë§ˆì§€ë§‰ feature map
- **ì‚¬ìš©ì²˜**: ë‚®ì€ ìˆ˜ì¤€ì˜ ì‹œê°ì  íŠ¹ì§• ë¶„ì„
- **ì„¤ëª…**:
  - 2048 = ResNet-50ì˜ ë§ˆì§€ë§‰ ì±„ë„ ìˆ˜
  - H, W = feature mapì˜ spatial ì°¨ì›

### 5) pred_logits
```
Shape: [100, 92]
Type: torch.FloatTensor
```
- **ì˜ë¯¸**: ê° queryì˜ class prediction logits
- **ì‚¬ìš©ì²˜**: Detection ê²°ê³¼, confidence ê³„ì‚°
- **ì„¤ëª…**:
  - 100 = queries
  - 92 = COCO classes (91) + no-object (1)

### 6) pred_boxes
```
Shape: [100, 4]
Type: torch.FloatTensor
```
- **ì˜ë¯¸**: ê° queryì˜ bounding box ì¢Œí‘œ
- **ì‚¬ìš©ì²˜**: Detection ê²°ê³¼, spatial ë¶„ì„
- **ì„¤ëª…**:
  - 4 = (center_x, center_y, width, height)
  - ê°’ ë²”ìœ„: [0, 1] (normalized)

---

## ğŸ’¡ 5. íŒŒì¼ ì½ê¸° ì˜ˆì œ

### Pythonì—ì„œ ì½ê¸°

```python
import torch

# ë‹¨ì¼ íŒŒì¼ ì½ê¸°
embedding = torch.load('embeddings_output/embedding_000000000001.pt')

print("Keys:", embedding.keys())
print("Query embeddings shape:", embedding['query_embeddings'].shape)
print("Predictions shape:", embedding['pred_logits'].shape)

# Query embeddings ì¶”ì¶œ
query_emb = embedding['query_embeddings']  # [100, 256]
print(f"Shape: {query_emb.shape}")
print(f"Mean: {query_emb.mean():.4f}")
print(f"Std: {query_emb.std():.4f}")

# Detection ê²°ê³¼ í™•ì¸
logits = embedding['pred_logits']         # [100, 92]
boxes = embedding['pred_boxes']           # [100, 4]

# Person class (COCO class 0)
person_probs = logits.softmax(-1)[:, 0]   # [100]
confident_detections = person_probs > 0.5
print(f"High confidence detections: {confident_detections.sum()}")
```

### Metadata ì½ê¸°

```python
import json

with open('embeddings_output/metadata.json', 'r') as f:
    metadata = json.load(f)

print(f"Total images: {metadata['num_images']}")
print(f"Image IDs: {metadata['image_ids'][:10]}...")  # ì²˜ìŒ 10ê°œ
print(f"Embedding keys: {metadata['embedding_keys']}")
```

---

## ğŸ“ 6. íŒŒì¼ í¬ê¸° ì˜ˆìƒ

### ë‹¨ì¼ ì´ë¯¸ì§€ë‹¹ í¬ê¸° (extract_typeë³„)

**decoder (ê¶Œì¥)**
- query_embeddings: 100 * 256 * 4 bytes = 100KB
- decoder_output: 6 * 100 * 256 * 4 bytes = 600KB
- encoder_output: ~850 * 256 * 4 bytes = ~850KB
- pred_logits: 100 * 92 * 4 bytes = 37KB
- pred_boxes: 100 * 4 * 4 bytes = 1.6KB
- **ì´ ì•½ 1.6MB/ì´ë¯¸ì§€**

**all**
- ìœ„ ë‚´ìš© + backbone_features: 2048 * 25 * 34 * 4 bytes = ~7MB
- **ì´ ì•½ 8-9MB/ì´ë¯¸ì§€**

**encoder**
- encoder_output + predictions
- **ì´ ì•½ 1MB/ì´ë¯¸ì§€**

**backbone**
- backbone_features + predictions
- **ì´ ì•½ 7-8MB/ì´ë¯¸ì§€**

### ì „ì²´ ë°ì´í„°ì…‹ í¬ê¸° ì˜ˆìƒ

| ì´ë¯¸ì§€ ìˆ˜ | decoder | all | encoder | backbone |
|----------|---------|-----|---------|----------|
| 100      | 160MB   | 900MB | 100MB | 800MB |
| 1,000    | 1.6GB   | 9GB   | 1GB   | 8GB   |
| 10,000   | 16GB    | 90GB  | 10GB  | 80GB  |

**ê¶Œì¥**: `extract_type='decoder'` ì‚¬ìš© ì‹œ ê°€ì¥ ì ì ˆí•œ ìš©ëŸ‰/ì •ë³´ ë¹„ìœ¨

---

## ğŸ¯ 7. ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ

### ëª¨ë“  ì„ë² ë”©ì„ numpy arrayë¡œ

```python
import torch
import numpy as np
from pathlib import Path

# ëª¨ë“  query embeddingsë¥¼ ìˆ˜ì§‘
embeddings_list = []
image_ids = []

output_dir = Path('embeddings_output')
for pt_file in sorted(output_dir.glob('embedding_*.pt')):
    emb = torch.load(pt_file)
    embeddings_list.append(emb['query_embeddings'].numpy())  # [100, 256]
    
    # íŒŒì¼ëª…ì—ì„œ image_id ì¶”ì¶œ
    image_id = int(pt_file.stem.split('_')[1])
    image_ids.append(image_id)

# í•˜ë‚˜ì˜ í° í–‰ë ¬ë¡œ ê²°í•©
all_embeddings = np.stack(embeddings_list, axis=0)  # [num_images, 100, 256]
print(f"All embeddings shape: {all_embeddings.shape}")

# í‰ê·  poolingìœ¼ë¡œ ê° ì´ë¯¸ì§€ë¥¼ ë‹¨ì¼ ë²¡í„°ë¡œ
image_vectors = all_embeddings.mean(axis=1)  # [num_images, 256]
print(f"Image vectors shape: {image_vectors.shape}")
```

### íŠ¹ì • ì´ë¯¸ì§€ë“¤ë§Œ ë¡œë“œ

```python
import json
import torch

# Metadataì—ì„œ ì´ë¯¸ì§€ ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
with open('embeddings_output/metadata.json', 'r') as f:
    metadata = json.load(f)

# ì²˜ìŒ 10ê°œ ì´ë¯¸ì§€ë§Œ
for image_id in metadata['image_ids'][:10]:
    emb_path = f'embeddings_output/embedding_{image_id:012d}.pt'
    emb = torch.load(emb_path)
    print(f"Image {image_id}: {emb['query_embeddings'].shape}")
```

---

## âœ… ìš”ì•½

### Output ìœ„ì¹˜
- **í´ë”**: `--output_dir`ë¡œ ì§€ì • (ê¸°ë³¸ê°’: `./embeddings_output`)
- **íŒŒì¼ ê°œìˆ˜**: ì´ë¯¸ì§€ ìˆ˜ + 1 (metadata.json)

### íŒŒì¼ í˜•ì‹
- **metadata.json**: JSON í…ìŠ¤íŠ¸ íŒŒì¼
- **embedding_*.pt**: PyTorch í…ì„œ ë”•ì…”ë„ˆë¦¬ (pickle)

### ì£¼ìš” ë‚´ìš©
- **query_embeddings** [100, 256]: ê°€ì¥ ì¤‘ìš”! ê° objectì˜ ì„ë² ë”©
- **pred_logits** [100, 92]: Detection class scores
- **pred_boxes** [100, 4]: Bounding box ì¢Œí‘œ

### ê¶Œì¥ ì‚¬ìš©
```bash
# Query embeddingsë§Œ ì¶”ì¶œ (ìš©ëŸ‰ íš¨ìœ¨ì )
python extract_embeddings.py \
    --extract_type decoder \
    --output_dir ./my_embeddings \
    ...
```

### ì½ê¸°
```python
import torch
emb = torch.load('embeddings_output/embedding_000000000001.pt')
query_emb = emb['query_embeddings']  # [100, 256]
```
